\section{Implementation (\textit{Jacob Salomonsen})}


\subsection{Matlab implementation analysis}
Since this was a blackbox-implementation scheme, it can be assumed that the programmer has no knowledge about the theory behind the model. The initial code analysis was done and gave an overview of the variables and procedures.

\begin{table}[htb]
	\centering
	\begin{tabular}{llp{6cm}}
		\toprule
		Variable & Type & Purpose \\
		\midrule
		F 				& $nx\times ny\times 9$ (double)	& eight directional matrices and one stationary state matrix\\
		FEQ 			& $nx\times ny\times 9$ (double)	& \\
		BOUNCEBACK		& $nx\times ny\times 9$ (double) & densities bouncing back\\
		BOUND 			& $nx\times ny$ (binary) 		& \\
		ON				& $8\times 1$ (integer) 			& linear index of directional matrices\\
		CI				& $b\times 1$ (integer)			& linear index of boundary nodes\\
		TO\_ REFLECT 	& $b\times 8$ (integer) 			& \\
		REFLECTED 		& $b\times 8$ (integer) 			& \\
		DENSITY			& & \\
		UX				& & \\
		UY				& & \\
		U\_ SQU			& & \\
		U\_ C2			& & \\
		U\_ C4			& & \\
		U\_ C6			& & \\
		U\_ C8			& & \\
		\bottomrule
	\end{tabular}
	\label{matlabvars}
	\caption{Matlab variables}
\end{table}


\subsection{NumPy}
NumPy is a scientific computing package for Python, which allows for multidimensional arrays, and routines for fast operations on these arrays. NumPy was used in implementing the CPU-version of the D2Q9-LBM. NumPy has the disadvantage that it will only run on one CPU, even in a multicore processor (TODO: add reference for this). This severely limits the potential for scientific computing using this package, but the usefulness of this package is that it is easy to prototype calculations.

At the core of the NumPy package is the \textit{ndarray}. The \textit{ndarray} is a statically allocated data structure, which upon creating cannot change in size. If an attempt to change the size of it is made it is simply overwritten. To allocate an array fitting with the data layout discussed in an earlier section (TODO: perhaps reference to the section here?), the following command is used:

\begin{verbatim}
>>> F = numpy.zeros((9,nx,ny), dtype=float)
\end{verbatim}

This allocates a three dimensional array consisting of zeros. Here the first dimension contains 9 spaces, and the other two dimensions contain the given width and height of the simulated field. The \texttt{dtype} parameter decides what data-type is to be used, in this case a float of no specification. 

As an alternative an array can be allocated with ones instead of zeros, which is useful for generating the scenery in the simulation field. This is simply done by the command

\begin{verbatim}
>>> BOUNDi = numpy.ones(BOUND.shape, dtype=float)
\end{verbatim}

Arrays have certain attributes attached to then which can be accessed by the dot operator. In the command above it can be seen that one of these attributes is accessed in the context of creating a new array, to make that array the same shape as another array. Here the meaning of the command is to create an array consisting of ones called \texttt{BOUNDi} in the shape of \texttt{BOUND}.

The type of operation which is mostly used in the LBM is the slicing operation. In the propagation kernel the data of the arrays need to "propagate" in specific directions. The slicing is used to move parts of the array around by assigning a shifted slice to the original matrix, while wrapping the end around to the beginning of the array. This of course requires careful consideration so as to avoid writing already shifted data which would lead to undesired results. This problem is easily solved by having a temporary store for the matrix and shifting the temporary matrix. The mechanics of this procedure is illustrated like this

\begin{tabular}{|c|c|c|}
\hline
1 & 2 & 3 \\
\hline
4 & 5 & 6 \\
\hline
7 & 8 & 9 \\
\hline
\end{tabular}

When dealing with data in an euclidean space it is important to remember that the array class in NumPy is column major. Therefore methods for example used for plotting data will expect the first dimension of a two-dimensional array to correspond with the y-axis of a normal plot. 

NumPy supports summation operations so as to be able to reduce the nine directional matrices. This is done by the use of the command

\begin{verbatim}
>>> DENSITY = numpy.add.reduce(F)
\end{verbatim}

Which produces the result of adding all the matrices along the first dimension, being the nine separate directional matrices. This could of course have been done even if the first dimension was not the directional matrices but instead the x-axis of the simulated field. Then an argument would have to be given to the \texttt{add.reduce} command to tell it along which axis to sum.

\begin{verbatim}
>>> DENSITY = numpy.add.reduce(F, axis=2)
\end{verbatim}

To expand a matrix with a new dimension, which is needed for the boundary calculations. Since the boundary matrix is only two dimensional it is necessary to expand upon it to be able to impose the boundary on the directional matrices. This is done by the command

\begin{verbatim}
>>> BOUND[numpy.newaxis,:,:]
\end{verbatim}



\subsection{PyCUDA}
PyCUDA is an extension for the Python language, that allows for full access to functionality available to CUDA C. Python is a scripting language, which means it is not compiled but interpreted. This leverages the programming process, and allows for some of the advantages of an interpreted language. One notable advantage over CUDA C is automatic resource control. Another advantage is the tight coupling with NumPy, which is especially good for the main purpose of this report. The testing procedure will gain more reliability by keeping the execution on the same platform.

PyCUDA allows a programmer trained in the usage of CUDA C, to easily start programming. Basically PyCUDA allows for CUDA C-code to be entered directly into the Python script. This is afforded by the \texttt{SourceModule}, which is a command used for creating CUDA-kernels. The \texttt{SourceModule} utilizes a just-in-time compilation process. (TODO: check fact!) This means that the kernel is only compiled at the moment it is needed.

As with CUDA C it is also necessary to load data onto the GPU by first allocating space and then copying to the GPU-memory. PyCUDA allows for allocating memory on the GPU using the \texttt{driver.mem\_ alloc} command, with argument for the size of the memory to allocate. The copying is performed with the \texttt{device.memcpy\_ htod}. Copying back from the GPU is afforded by the command \texttt{driver.memcpy\_ dtoh}. These commands allocate global memory on the GPU by default. (TODO: check whether the copy is just for a pointer to the python buffer or if data is loaded into gpu-memory)

To further specify what kind of float the command from above can be augmented with the following statement

\begin{verbatim}
>>> F = numpy.zeros((9,nx,ny), dtype=float).astype(numpy.float32)
\end{verbatim}

This allocates 32-bit floats which is especially suited for CUDA.


\newpage
\subsection{Design choices}
In this section the choices made during the implementation of the D2Q9 LBM will described. The implementation takes origin in the Matlab code included in \hpref{listing}{lbmmatlab}.

To be able to perform a proper comparison between the CPU-- and GPU--version of the model, a NumPy version has been created also taking origin in the Matlab code. This allows for the same benchmarking technique within the Python code, using the (TODO: insert library name here).

\subsubsection{Data layout}
The D2Q9 LBM maintains velocities for eight directional states plus one stationary state per point in the simulated field. If the dimension of the simulated field is $x \cdot y$ then to be able to contain this, the data structure must be able to contain $9 \cdot x \cdot y$.

\subsubsection{NumPy}
Since Python (and NumPy) is reminiscent of Matlab, there are no significant differences between the Matlab-- and NumPy--version. The largest difference lies in the above method for wrapping an array and the way the boundary is imposed on the directional matrices. This is done by using two matrices, one normal and one inverted matrix containing zeros for the locations of boundaries and ones for the locations of free space. The normal matrix is used for selecting only the nodes in the boundary so as to save their propagational state for later use in the bounceback section. The inverted boundary matrix is then multiplied on the eight directional matrices which results in an erasure of all other than the boundary nodes' stationary matrix. Using the saved state from the boundary nodes velocities are then transferred back in an inverted pattern, as described in the (TODO: refer to code analysis section).

\subsubsection{PyCUDA}







